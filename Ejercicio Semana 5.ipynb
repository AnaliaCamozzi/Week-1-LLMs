{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## Trabajador experto en conocimiento\n",
    "\n",
    "Un agente que responde preguntas y es un trabajador experto en conocimiento\n",
    "En este caso lo voy a utilizar para el emprendimiento que estamos trabajando con mis dos socios, Estudio3. Estudio3.ar\n",
    "El agente va a responder información especifica de Estudio3, que obtendra da la pagina web, y la solución debe ser de bajo costo, intentare hacerlo con Open IA y luego con algun modelo de codigo abierto.\n",
    "\n",
    "Utilizará RAG (Retrieval Augmented Generation, generación aumentada de recuperación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2040988d-ac5d-4fdf-afe1-9044414eaa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (0.3.16)\n",
      "Requirement already satisfied: pymupdf in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (1.25.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (0.3.32)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (0.2.11)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c12a496-ea8f-4eb7-b9a3-7407402c9ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth-oauthlib in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from google-auth-oauthlib) (2.38.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from google-auth-oauthlib) (2.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.32.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-auth-oauthlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replico la importacion usual\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports de langchain, plotly y Chroma\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66081a35-4852-4a46-b99e-d38293fe305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comienzo con OPENIA\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levanto las keys desde .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005c759-b9b5-4a54-9cbb-ec77e0fd8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "## le agrego llamar al google drive de mi emprendimiento\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import pickle\n",
    "\n",
    "# Archivo JSON de credenciales (asegúrate de que esté en el mismo directorio que tu código)\n",
    "CLIENT_SECRET_FILE = \"credentials.json\"\n",
    "SCOPES = [\"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "# Autenticación con OAuth 2.0\n",
    "flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)\n",
    "creds = flow.run_local_server(port=0)\n",
    "\n",
    "# Guardar credenciales para futuras sesiones\n",
    "with open(\"token.pickle\", \"wb\") as token:\n",
    "    pickle.dump(creds, token)\n",
    "\n",
    "# Construcción del servicio de Google Drive\n",
    "drive_service = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "# Listar archivos en Drive para verificar acceso\n",
    "results = drive_service.files().list(pageSize=10, fields=\"files(id, name)\").execute()\n",
    "files = results.get(\"files\", [])\n",
    "\n",
    "if not files:\n",
    "    print(\"No se encontraron archivos en Google Drive.\")\n",
    "else:\n",
    "    print(\"Archivos en Drive:\")\n",
    "    for file in files:\n",
    "        print(f\"{file['name']} ({file['id']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b88c69ab-5edf-482a-8f36-5f2397ccc181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto guardado en: Estudio3-base/Servicios/OnePager_Estudio3_Servicios.md\n"
     ]
    }
   ],
   "source": [
    "#aqui le indico leer solo un archivo, es para probar y luego extender es un gogole slide. \n",
    "#habilite la API de google slide\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"token.pickle\", \"rb\") as token:\n",
    "    creds = pickle.load(token)\n",
    "\n",
    "\n",
    "slides_service = build(\"slides\", \"v1\", credentials=creds)\n",
    "\n",
    "# ID del archivo Google Slides\n",
    "PRESENTATION_ID = \"1FyLW3R2wcqPL3nnibzbtLp-h6Y6AJFefepBxaqPIE2s\"\n",
    "\n",
    "\n",
    "presentation = slides_service.presentations().get(presentationId=PRESENTATION_ID).execute()\n",
    "\n",
    "# Establecer el folder path, se suma a la carpeta servicios\n",
    "folder_path = \"Estudio3-base/Servicios\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Ruta del archivo donde se guardará el texto\n",
    "file_path = os.path.join(folder_path, \"OnePager_Estudio3_Servicios.md\")\n",
    "\n",
    "# Extraer texto y guardarlo en el archivo\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for slide in presentation.get(\"slides\", []):\n",
    "        file.write(f\"Diapositiva {slide['objectId']}:\\n\")\n",
    "        slide_text = []  # Lista para almacenar el texto de la diapositiva\n",
    "        \n",
    "        for element in slide.get(\"pageElements\", []):\n",
    "            if \"shape\" in element and \"text\" in element[\"shape\"]:\n",
    "                text_elements = element[\"shape\"][\"text\"].get(\"textElements\", [])\n",
    "                for text_element in text_elements:\n",
    "                    if \"textRun\" in text_element:\n",
    "                        slide_text.append(text_element[\"textRun\"][\"content\"].strip())\n",
    "\n",
    "        # Escribir solo si hay texto en la diapositiva\n",
    "        if slide_text:\n",
    "            file.write(\"\\n\".join(slide_text) + \"\\n\")\n",
    "\n",
    "        file.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "print(f\"Texto guardado en: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "730711a9-6ffe-4eee-8f48-d6cfb7314905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 6735, which is longer than the specified 1000\n",
      "Created a chunk of size 2966, which is longer than the specified 1000\n",
      "Created a chunk of size 8026, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 41\n",
      "Document types found: {'Presupuestos', 'Servicios', 'Estudio3', 'Founders'}\n"
     ]
    }
   ],
   "source": [
    "## Le agrego que lea tambien PDF \n",
    "\n",
    "folders = glob.glob(\"Estudio3-base/*\")\n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "\n",
    "    # Cargar archivos .md\n",
    "    md_loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    md_docs = md_loader.load()\n",
    "    \n",
    "    # Cargar archivos .pdf\n",
    "    pdf_loader = DirectoryLoader(folder, glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "    pdf_docs = pdf_loader.load()\n",
    "\n",
    "    # Agregar metadata y combinar documentos\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in md_docs + pdf_docs])\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78998399-ac17-4e28-b15f-0b5f51e6ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 41 documents\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Crear almacén de vectores\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff2e7687-60d4-4920-a1d7-a34b9f70a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 41 vectores con 1,536 dimensiones en el almacén de vectores\n"
     ]
    }
   ],
   "source": [
    "# Investiguemos los vectores\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"Hay {count:,} vectores con {dimensions:,} dimensiones en el almacén de vectores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "129c7d1e-0094-4479-9459-f9360b95f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8w/cpvgvw0n1c19hc1_clypdl000000gn/T/ipykernel_33579/3693541071.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# Chat \n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# Setear la memoria\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# Agrego la cantidad a revisar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 60})\n",
    "\n",
    "# juntando todo: configure la cadena de conversación con GPT 3.5 LLM, el almacén vectorial y la memoria\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b5a9013-d5d4-4e25-9e7c-cdbb4f33e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a new conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 4o-mini LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3536590-85c7-4155-bd87-ae78a1467670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping that in a function\n",
    "\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30b4745a-0a6c-4544-b78b-c827cfec1fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/components/chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/chat_interface.py:317: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://47e3ee144b72293133.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://47e3ee144b72293133.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración de la interfaz mejorada\n",
    "view = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    title=\"🤖 Asistente Virtual de Estudio 3\",\n",
    "    description=\"Hola! Soy el asistente virtual de E3, ¿cómo podemos ayudarte hoy?\",\n",
    "    theme=\"soft\",  # Tema con bordes redondeados y colores suaves\n",
    "    chatbot=gr.Chatbot(height=400)  # Ajuste de altura del chat\n",
    ")\n",
    "\n",
    "# Estilos adicionales\n",
    "css = \"\"\"\n",
    ".chatbot-container {\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    background-color: #f8f8f8;\n",
    "    border-radius: 10px;\n",
    "    padding: 10px;\n",
    "}\n",
    ".gradio-title {\n",
    "    color: #2a5d67;\n",
    "    font-weight: bold;\n",
    "    font-size: 1.5em;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "view.launch(share=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
